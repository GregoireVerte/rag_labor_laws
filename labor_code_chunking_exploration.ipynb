{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a18aa5-0489-4a8f-9e33-fb49cad6081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 477 jednostek redakcyjnych (artykułów).\n",
      "\n",
      "Przykład artykułu 1 (Art. 1):\n",
      "U S T AWA \n",
      "z dnia 26 czerwca 1974 r. \n",
      "Kodeks pracy1) \n",
      "Preambuła (uchylona) \n",
      " \n",
      "1) Niniejsza ustawa dokonuje w  zakresie swojej regulacji wdrożenia następujących dyrektyw \n",
      "Wspólnot Europejskich: \n",
      "1) dyrektywy 83/477/EWG z dnia 19 września 1983 r. w sprawie ochrony pracowników przed \n",
      "ryzykiem związanym\n",
      "\n",
      "Przykład artykułu ze środka:\n",
      "Art. 612. § 1. Odszkodowanie, o  którym mowa w  art. 611, przysługuje \n",
      "w wysokości wynagrodzenia pracownika za okres wypowiedzenia. W  przypadku \n",
      "rozwiązania umowy o  pracę zawartej na czas określony, odszkodowanie \n",
      "przysługuje w wysokości wynagrodzenia za czas, do którego umowa miała trwać, \n",
      "nie wi\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. Wczytanie dokumentu\n",
    "file_path = \"last_unified_labor_code.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "# 2. Łączenie wszystkich stron w jeden tekst i proste czyszczenie szumu\n",
    "full_text = \"\"\n",
    "for page in pages:\n",
    "    content = page.page_content\n",
    "    # Usuwanie stopki (©Kancelaria Sejmu + data + numer strony)\n",
    "    # Regex dopasuje np. \"©Kancelaria Sejmu s. 5/185\" oraz datę pod spodem\n",
    "    content = re.sub(r\"©Kancelaria Sejmu.*s\\.\\s\\d+/\\d+\", \"\", content)\n",
    "    content = re.sub(r\"2026-02-03\", \"\", content) # usuwa datę generowania\n",
    "    full_text += content + \"\\n\"\n",
    "\n",
    "# 3. Funkcja do podziału na artykuły\n",
    "def split_into_articles(text):\n",
    "    # Szuka wzorca: \"Art. [liczba i ewentualnie litera].\"\n",
    "    # Używa (?=Art\\.) aby zachować \"Art.\" na początku każdego chunka\n",
    "    pattern = r\"(?=Art\\.\\s+\\d+[a-z]*\\.)\"\n",
    "    chunks = re.split(pattern, text)\n",
    "    \n",
    "    # Usuwa ewentualny pusty pierwszy element i białe znaki\n",
    "    chunks = [c.strip() for c in chunks if c.strip()]\n",
    "    return chunks\n",
    "\n",
    "articles = split_into_articles(full_text)\n",
    "\n",
    "# podgląd\n",
    "print(f\"Znaleziono {len(articles)} jednostek redakcyjnych (artykułów).\")\n",
    "print(\"\\nPrzykład artykułu 1 (Art. 1):\")\n",
    "print(articles[0][:300])\n",
    "print(\"\\nPrzykład artykułu ze środka:\")\n",
    "print(articles[100][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478d0d24-de39-40ce-8b1d-115d8b1e6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przygotowano 477 obiektów z metadanymi.\n",
      "Przykładowy wpis (indeks 5):\n",
      "Metadane: {'art_id': 'Art. 4', 'source': 'Kodeks Pracy', 'status_date': '2026-02-03', 'chunk_id': 5}\n",
      "Treść (początek): Art. 4. (uchylony)...\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "for i, chunk in enumerate(articles):\n",
    "    # 1. Wyciąga numer artykułu z początku tekstu (np. \"Art. 1.\") ## szuka wzorca na samym początku chunka\n",
    "    match = re.search(r\"Art\\.\\s+(\\d+[a-z]*)\", chunk)\n",
    "    \n",
    "    if match:\n",
    "        art_number = f\"Art. {match.group(1)}\"\n",
    "    else:\n",
    "        # jeśli to pierwszy chunk (ten z tytułem i preambułą)\n",
    "        art_number = \"Wstęp/Tytuł\"\n",
    "\n",
    "    # 2. Tworzy słownik z metadanymi\n",
    "    metadata = {\n",
    "        \"art_id\": art_number,\n",
    "        \"source\": \"Kodeks Pracy\",\n",
    "        \"status_date\": \"2026-02-03\",\n",
    "        \"chunk_id\": i\n",
    "    }\n",
    "    \n",
    "    # 3. Dodajemy do listy gotowy obiekt\n",
    "    processed_data.append({\n",
    "        \"content\": chunk,\n",
    "        \"metadata\": metadata\n",
    "    })\n",
    "\n",
    "# test\n",
    "print(f\"Przygotowano {len(processed_data)} obiektów z metadanymi.\")\n",
    "print(f\"Przykładowy wpis (indeks 5):\")\n",
    "print(f\"Metadane: {processed_data[5]['metadata']}\")\n",
    "print(f\"Treść (początek): {processed_data[5]['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55fde3-79fa-4cd9-a057-a765b2d7523b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311env",
   "language": "python",
   "name": "pyth311env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
